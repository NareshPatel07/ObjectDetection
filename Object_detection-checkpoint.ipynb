{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "04b60257-2c25-4905-8666-c5a48cace65c",
   "metadata": {},
   "source": [
    "# **Object Detection [Classification+Localization]**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cefb7766-3612-4d03-a1e0-a42d5b6f9fb3",
   "metadata": {},
   "source": [
    "# 1:Importing libaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "51fbe040-ee25-4312-a434-fe419b787dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "04b198d5-2bc8-43ed-8284-933cf6224329",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import PIL.Image,PIL.ImageFont,PIL.ImageDraw\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f0ebb63-6436-4ee4-9636-174dbb810d89",
   "metadata": {},
   "source": [
    "## **2: Visualization Utilities**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cf170cb3-4959-41ed-8ada-e08042d892bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "im_width =75\n",
    "im_height =75\n",
    "use_normalized_coordiates = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2db80361-40a5-49f7-91f6-7f4b1c9d3fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_bounding_boxes_on_images_array(image,boxes,color=[],thickness =1 ,display_str_list=()):\n",
    "    imagge.pil = PIL.Image.fromarray(image)\n",
    "    rgbimg= PIL.Image.new(\"RGBA\",image_pil.size)\n",
    "    rgbimg.paste(image_pil)\n",
    "    draw_bounding_boxes_on_images(image,boxes,color=[],thickness =1 ,display_str_list=())\n",
    "    return np.array(rgbimg)\n",
    "\n",
    "def draw_bounding_boxes_on_images(image,boxes,color=[],thickness =1 ,display_str_list=()):\n",
    "    boxes_shape= boxes.shape\n",
    "    if not boxes_shape:\n",
    "        return \n",
    "    if len(boxes_shape)!=2 or boxes_shape[1]!=4:\n",
    "        raise ValueError(\"Input must be of size[N,4]\")\n",
    "    for i in range(boxes_shape[0]):\n",
    "        draw_bounding_boxes_on_image(image,boxes[i,1],boxes[i,0],boxes[i,3],boxes[i,2],color[i],thickness,display_str_list[i])\n",
    "\n",
    "def draw_bounding_boxes_on_images(image,ymin,xmin,ymax,xmax,colors ='red',thickness = 1,use_normalized_coordiates = True):\n",
    "    draw = PIL.ImageDraw.Draw(image)\n",
    "    im_width,im_height = image.size\n",
    "    if use_normalized_coordiates:\n",
    "        (left,right,top,bottom) = (xmin*im_width, xmax*im_width,\n",
    "                                   ymin*im_height, ymax*im_height)\n",
    "    else:\n",
    "        (left,rigth,top,bottom) = (xmin,xmax,ymin,ymax)\n",
    "    draw.line([(left,top),(left,bottom),(right,bottom),(right,top),(left,top)],width = thickness,fill =color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "80fce90e-dfcd-4bb4-a3ca-33e94c3f6c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_to_numpy_util(training_dataset, validation_dataset, N):\n",
    "    batch_train_ds = training_dataset.unbatch().batch(N)\n",
    "    batch_val_ds = validation_dataset.unbatch().batch(N)\n",
    "\n",
    "    if tf.executing_eagerly():\n",
    "        for validation_digits, (validation_labels, validation_boxes) in validation_dataset:\n",
    "            validation_digits = validation_digits.numpy()\n",
    "            validation_labels = validation_labels.numpy()\n",
    "            validation_boxes = validation_boxes.numpy()\n",
    "            break\n",
    "\n",
    "        for training_digits, (training_labels, training_boxes) in training_dataset:\n",
    "            training_digits = training_digits.numpy()\n",
    "            training_labels = training_labels.numpy()\n",
    "            training_boxes = training_boxes.numpy()\n",
    "            break\n",
    "\n",
    "        validation_labels = np.argmax(validation_labels,axis=1)\n",
    "        training_labels = np.argmax(training_labels,axis=1)\n",
    "        return (training_digits,training_labels,training_boxes,\n",
    "                 validation_digits,validation_labels,validation_boxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "826668ab-f389-41c1-8106-0b194c03fcea",
   "metadata": {},
   "outputs": [],
   "source": [
    "MATPLOTLIB_FONT_DIR = os.path.join(os.path.dirname(plt.__file__),\"mpl-data/fonts/ttf\")\n",
    "\n",
    "def create_digits_from_local_fonts(n):\n",
    "    font_labels =[]\n",
    "    img = PIL.Image.new('LA',(75*n,75),color=(0,255))\n",
    "    font1=PIL.ImageFont.truetype(os.path.join(MATPLOTLIB_FONT_DIR,'DejaVuSansMono-Oblique.ttf'),25)\n",
    "    font2=PIL.ImageFont.truetype(os.path.join(MATPLOTLIB_FONT_DIR,'STIXGeneral.ttf'),25)\n",
    "    d= PIL.ImageDraw.Draw(img)\n",
    "    for i in range(n):\n",
    "        font_labels.append(i%10)\n",
    "        d.text((7+i%75,0 if i<0 else -4),str(i%10),fill=(255,255),font = font1 if i<0 else font2)\n",
    "    font_digits = np.array(img.getdata().np.float32)[:0]/255.0\n",
    "    font_digits = np.reshape(np.stack(np.split(np.reshape(font_digits,[75,75*n]),n,axis=1),axis=0)[n,75*75])\n",
    "    return font_digits,font_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "240bde02-7747-43d9-8333-81bda53b955c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_digits_with_boxes(digits,predications,pred_boxes,boxes,iou,title):\n",
    "\n",
    "    n=10\n",
    "    indexes  = np.random.choice(len(predications),size =n)\n",
    "    n_digits = digits[indexes]\n",
    "    n_predictions = predications[indexes]\n",
    "    n_labels = labels[indexes]\n",
    "\n",
    "    n_iou =[]\n",
    "    if len(iou) > 0:\n",
    "        n_iou =iou[indexes]\n",
    "    if len(pred_boxes)>0:\n",
    "        n_pred_boxes = pred_boxes[indexes]\n",
    "    if len(boxes)>0:\n",
    "        n_boxes= boxes[indexes]\n",
    "\n",
    "    n_digits = n_digits *255.0\n",
    "    n_digits = n_digits.reshape(n,75,75)\n",
    "    fig = plt.figure(figsize=(20,4))\n",
    "    plt.title(title)\n",
    "    plt.xtricks([])\n",
    "    plt.ytricks([])\n",
    "\n",
    "    for i in range(10):\n",
    "        ax = fig.add_subplot(1,10,i+1)\n",
    "        boxes_to_plot =[]\n",
    "        if(len(pred_boxes)>i):\n",
    "            boxes_to_plot.append(n_pred_boxes[i])\n",
    "\n",
    "        if(len(boxes)>i):\n",
    "            boxes_to_plot.append(n_boxes[i])\n",
    "\n",
    "        img_to_draw = draw_bounding_boxes_on_images_array(image = n_digits[i],\n",
    "                                                          boxes = np.asarray(boxes_to_plot),\n",
    "                                                          color = ['red','green'],\n",
    "                                                          display_str_list =[\"True\",\"Pred\"])\n",
    "        plt.xlabel(n_predictions[i])\n",
    "        plt.xtricks([])\n",
    "        plt.ytricks([])\n",
    "        if n_predictions[i]!= n_labels[i]:\n",
    "            ax.xais.label.set_color('red')\n",
    "        plt.imshow(img_to_draw)\n",
    "\n",
    "        if len(iou)>i:\n",
    "            color =\"black\"\n",
    "            if(n_iou[i][0]<ioy_threshold):\n",
    "                color = \"red\"\n",
    "            ax.text(0.2,-0.3, \"iou: %s\" %(n_iou[i][0]),color=color, transform= ax.transAxes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "854a4a29-95c9-4061-b9a1-a4ae25a9474e",
   "metadata": {},
   "source": [
    "#**3.Loading and Preprocessing the dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a6e2453b-f557-41be-9f77-bd4ec636b309",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of replicas in sync: 1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "strategy = tf.distribute.get_strategy()\n",
    "print(\"Number of replicas in sync:\", strategy.num_replicas_in_sync)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "014b43ad-5822-452e-924e-87b46b0d1dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#BATCH_SIZE =64*strategy.num_replicas_in_sync\n",
    "BATCH_SIZE =64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "d903f23e-e282-4245-a209-a3012779c487",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_image_tfds(image,label):\n",
    "    xmin =tf.random.uniform((),0,48,dtype = tf.int32)\n",
    "    ymin =tf.random.uniform((),0,48,dtype = tf.int32)\n",
    "    image = tf.reshape(image,(28,28,1))\n",
    "    image = tf.image.pad_to_bounding_box(image,ymin,xmin,75,75)\n",
    "    image = tf.cast(image,tf.float32)/255.0\n",
    "    xmin = tf.cast(xmin,tf.float32)\n",
    "    ymin = tf.cast(ymin,tf.float32)\n",
    "\n",
    "    xmax =(xmin+28)/75\n",
    "    ymax = (ymin+28)/75\n",
    "    xmin = xmin/75\n",
    "    ymax = ymax/75\n",
    "    return image,(tf.one_hot(label,10),[xmin,ymin,xmax,ymax])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "01ec0fbd-9422-4e0e-9061-74456d9ce300",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_training_dataset():\n",
    "    with strategy.scope():\n",
    "        dataset = tfds.load(\"mnist\",split = \"train\",as_supervised = True, try_gcs = True)\n",
    "        dateset = dataset.map(read_image_tfds, num_parallel_calls = 16)\n",
    "        dataset = dataset.shuffle(5000, reshuffle_each_iteration = True)\n",
    "        dataset = dataset.repeat()\n",
    "        dataset = dataset.batch(BATCH_SIZE, drop_remainder = True)\n",
    "        dataset = dataset.prefetch(-1)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "fc80e15e-4a53-4767-a9f1-28417515b50d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_validation_dataset():\n",
    "    with strategy.scope():\n",
    "        dataset = tfds.load(\"mnist\",split = \"train\",as_supervised = True, try_gcs = True)\n",
    "        dateset = dataset.map(read_image_tfds, num_parallel_calls = 16)\n",
    "        dataset = dataset.batch(10000, drop_remainder = True)\n",
    "        dataset = dataset.repeat()\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "dbadb908-cfb2-42bd-8d5e-e3e11d8e1b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "with strategy.scope():\n",
    "    training_dataset = get_training_dataset()\n",
    "    validation_dataset = get_validation_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "6697f922-5226-49f8-952a-3f98523a6db6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[70]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m (training_digits, training_labels, training_boxes, \n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m  validation_digits, validation_labels, validation_boxes) = \u001b[43mdataset_to_numpy_util\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtraining_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[52]\u001b[39m\u001b[32m, line 6\u001b[39m, in \u001b[36mdataset_to_numpy_util\u001b[39m\u001b[34m(training_dataset, validation_dataset, N)\u001b[39m\n\u001b[32m      3\u001b[39m batch_val_ds = validation_dataset.unbatch().batch(N)\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m tf.executing_eagerly():\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m validation_digits, (validation_labels, validation_boxes) \u001b[38;5;129;01min\u001b[39;00m validation_dataset:\n\u001b[32m      7\u001b[39m         validation_digits = validation_digits.numpy()\n\u001b[32m      8\u001b[39m         validation_labels = validation_labels.numpy()\n",
      "\u001b[31mValueError\u001b[39m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "(training_digits, training_labels, training_boxes, \n",
    " validation_digits, validation_labels, validation_boxes) = dataset_to_numpy_util(training_dataset, validation_dataset, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4c834ff-cc4c-4d4c-841f-776ec83c84df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "734c117a-2546-4c86-a227-a0a5b73724d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "468c0066-b59c-4bc8-b19f-7de6531ecde3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe68b2e9-8a4e-4a18-936e-9a37aae35e39",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:Naresh]",
   "language": "python",
   "name": "conda-env-Naresh-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
